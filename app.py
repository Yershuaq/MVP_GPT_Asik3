import streamlit as st
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader
from langchain.text_splitter import TokenTextSplitter
from langchain_ollama import OllamaEmbeddings
from langchain_ollama import ChatOllama
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
import tempfile
import os

st.set_page_config(page_title="–ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω—ã–π –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –†–ö –Ω–∞ Ollama", page_icon="üìö")
st.title("ü§ñ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–ö (–Ω–∞ –±–∞–∑–µ Ollama)")

OLLAMA_BASE_URL = st.sidebar.text_input("–ê–¥—Ä–µ—Å —Å–µ—Ä–≤–µ—Ä–∞ Ollama (–µ—Å–ª–∏ –Ω–µ localhost:11434)", "http://localhost:11434")
OLLAMA_EMBED_MODEL = st.sidebar.text_input("–ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ Ollama", "nomic-embed-text")
OLLAMA_CHAT_MODEL = st.sidebar.text_input("–ß–∞—Ç-–º–æ–¥–µ–ª—å Ollama", "llama2")

if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = None
if "messages" not in st.session_state:
    st.session_state.messages = []
if "ollama_setup_valid" not in st.session_state:
    st.session_state.ollama_setup_valid = False
if "embeddings" not in st.session_state:
    st.session_state.embeddings = None
if "llm" not in st.session_state:
    st.session_state.llm = None


def check_ollama_availability():
    try:
        st.session_state.embeddings = OllamaEmbeddings(
            model=OLLAMA_EMBED_MODEL,
            base_url=OLLAMA_BASE_URL
        )
        st.session_state.llm = ChatOllama(
            model=OLLAMA_CHAT_MODEL,
            base_url=OLLAMA_BASE_URL,
            temperature=0
        )
        st.session_state.ollama_setup_valid = True
        st.sidebar.success(f"Ollama –Ω–∞—Å—Ç—Ä–æ–µ–Ω: Embed: {OLLAMA_EMBED_MODEL}, Chat: {OLLAMA_CHAT_MODEL}")
    except Exception as e:
        st.sidebar.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama –∏–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {e}")
        st.session_state.ollama_setup_valid = False
        st.session_state.embeddings = None
        st.session_state.llm = None


if st.sidebar.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama"):
    check_ollama_availability()


def process_document(file):
    tmp_file_path = ""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.name)[1]) as tmp_file:
            tmp_file.write(file.getvalue())
            tmp_file_path = tmp_file.name

        if file.name.endswith('.pdf'):
            loader = PyPDFLoader(tmp_file_path)
        elif file.name.endswith('.docx'):
            loader = Docx2txtLoader(tmp_file_path)
        else:
            st.error("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ PDF –∏ DOCX —Ñ–∞–π–ª—ã")
            return None

        documents = loader.load()
        text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=100)
        splits = text_splitter.split_documents(documents)
        return splits
    finally:
        if tmp_file_path and os.path.exists(tmp_file_path):
            os.unlink(tmp_file_path)


uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ PDF –∏–ª–∏ DOCX —Ñ–∞–π–ª —Å –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–µ–π", type=['pdf', 'docx'])

if uploaded_file and st.session_state.ollama_setup_valid and st.session_state.embeddings:
    with st.spinner(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ '{uploaded_file.name}'..."):
        splits = process_document(uploaded_file)
        if splits:
            try:
                st.session_state.vectorstore = FAISS.from_documents(splits, st.session_state.embeddings)
                st.success(f"–î–æ–∫—É–º–µ–Ω—Ç '{uploaded_file.name}' —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π!")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞: {e}")
                st.session_state.vectorstore = None
        else:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —á–∞—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞.")

elif uploaded_file and (not st.session_state.ollama_setup_valid or not st.session_state.embeddings):
    st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –∏ –ø—Ä–∏–º–µ–Ω–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã Ollama –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π —Ñ–∞–π–ª–∞.")

if st.session_state.vectorstore and st.session_state.ollama_setup_valid and st.session_state.llm:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
            if "sources" in message and message["sources"]:
                with st.expander("–ò—Å—Ç–æ—á–Ω–∏–∫–∏"):
                    for i, source_content in enumerate(message["sources"]):
                        st.markdown(f"**–ò—Å—Ç–æ—á–Ω–∏–∫ {i + 1}:**")
                        st.text_area(label=f"src_{i}_{message['role']}_{i}", value=source_content, height=100,
                                     disabled=True, label_visibility="collapsed",
                                     key=f"src_{message['role']}_{i}_{source_content[:10]}")

    if prompt := st.chat_input("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†K"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)

        with st.chat_message("assistant"):
            with st.spinner("–ò–¥–µ—Ç –ø–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–∞..."):
                try:
                    qa_chain = RetrievalQA.from_chain_type(
                        llm=st.session_state.llm,
                        chain_type="stuff",
                        retriever=st.session_state.vectorstore.as_retriever(search_kwargs={"k": 3}),
                        return_source_documents=True
                    )

                    response = qa_chain.invoke({"query": prompt})  # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ .invoke –¥–ª—è –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π Langchain
                    result_text = response.get("result", "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç.")
                    source_documents = response.get("source_documents", [])

                    st.write(result_text)

                    sources_content = []
                    if source_documents:
                        with st.expander("–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –æ—Ç–≤–µ—Ç–∞"):
                            for i, doc in enumerate(source_documents):
                                st.markdown(f"**–ò—Å—Ç–æ—á–Ω–∏–∫ {i + 1} (—á–∞—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞):**")
                                st.text_area(label=f"res_src_{i}", value=doc.page_content, height=100, disabled=True,
                                             label_visibility="collapsed", key=f"res_src_{i}_{doc.page_content[:10]}")
                                sources_content.append(doc.page_content)

                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": result_text,
                        "sources": sources_content
                    })
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM: {e}")
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}",
                        "sources": []
                    })
elif not st.session_state.ollama_setup_valid:
    st.info(
        "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã Ollama –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ —Å–ª–µ–≤–∞ –∏ –Ω–∞–∂–º–∏—Ç–µ '–ü—Ä–∏–º–µ–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama'. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à —Å–µ—Ä–≤–µ—Ä Ollama –∑–∞–ø—É—â–µ–Ω —Å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏.")
elif not st.session_state.vectorstore and uploaded_file:
    st.info("–ò–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ Ollama. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
elif not st.session_state.vectorstore:
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç —Å –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–µ–π –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã.")